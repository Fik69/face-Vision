<!DOCTYPE html>
<html>
<head>
    <title>Working face-api.js Example</title>
    <!-- Load from author's GitHub -->
    <script src="https://justadudewhohacks.github.io/face-api.js/face-api.min.js"></script>
    <style>
        body { font-family: sans-serif; text-align: center; margin-top: 50px; }
        #status { padding: 20px; margin: 20px auto; max-width: 500px; border-radius: 5px; }
        .loading { background: #fff3cd; color: #856404; }
        .success { background: #d4edda; color: #155724; }
        .error { background: #f8d7da; color: #721c24; }
    </style>
</head>
<body>
    <h1>Passport Photo Maker</h1>
    <div id="status" class="loading">Initializing...</div>
    <video id="video" width="400" height="300" autoplay muted></video>
    <button id="capture" disabled>Capture</button>
    <canvas id="canvas" width="400" height="300" style="display:none;"></canvas>
    
    <script>
        // Configuration - Using author's GitHub Pages
        const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
        
        // Elements
        const statusEl = document.getElementById('status');
        const videoEl = document.getElementById('video');
        const canvasEl = document.getElementById('canvas');
        const captureBtn = document.getElementById('capture');
        
        async function init() {
            try {
                // 1. Load models
                statusEl.textContent = "Loading face detection models...";
                await faceapi.loadTinyFaceDetectorModel(MODEL_URL);
                
                // 2. Setup camera
                statusEl.textContent = "Accessing camera...";
                const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
                videoEl.srcObject = stream;
                
                // 3. Enable UI
                statusEl.textContent = "Ready! Center your face in the frame";
                statusEl.className = "success";
                captureBtn.disabled = false;
                
                // 4. Setup capture handler
                captureBtn.addEventListener('click', async () => {
                    // Draw video frame to canvas
                    canvasEl.width = videoEl.videoWidth;
                    canvasEl.height = videoEl.videoHeight;
                    canvasEl.getContext('2d').drawImage(videoEl, 0, 0);
                    
                    // Detect face
                    const detection = await faceapi.detectSingleFace(
                        canvasEl, 
                        new faceapi.TinyFaceDetectorOptions()
                    );
                    
                    if (detection) {
                        statusEl.textContent = "Face detected!";
                        alert("Success! Face detected at position: " + JSON.stringify(detection.box));
                    } else {
                        statusEl.textContent = "No face detected - try again";
                        statusEl.className = "error";
                    }
                });
                
            } catch (error) {
                statusEl.textContent = `Error: ${error.message}`;
                statusEl.className = "error";
                console.error("Initialization failed:", error);
            }
        }
        
        // Start the app
        init();
    </script>
</body>
</html>